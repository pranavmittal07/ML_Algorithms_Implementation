{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T15:50:40.583387Z","iopub.execute_input":"2025-01-23T15:50:40.583607Z","iopub.status.idle":"2025-01-23T15:50:40.596470Z","shell.execute_reply.started":"2025-01-23T15:50:40.583586Z","shell.execute_reply":"2025-01-23T15:50:40.595478Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/iris/Iris.csv\n/kaggle/input/iris/database.sqlite\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/iris/Iris.csv')\n\n# Convert the 'Species' column to numeric labels\ndf['Species'] = df['Species'].map({'Iris-setosa': 0, 'Iris-virginica': 1, 'Iris-versicolor': 2})\n\n# Select features (ensure they are numeric)\nX = df.iloc[:, 1:-1]  # Ensure all data is numeric\ny = df.iloc[:, -1]\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# KNN Classifier Class\nclass KNN:\n    def __init__(self, k=3):\n        self.k = k\n\n    def fit(self, X_train, y_train):\n        self.X_train = X_train.values  # Convert to NumPy array\n        self.y_train = y_train.values  # Convert to NumPy array\n\n    def euclidean_distance(self, a, b):\n        # Ensure a and b are numpy arrays for element-wise subtraction\n        return np.sqrt(np.sum((a - b) ** 2, axis=1))\n\n    def predict(self, X_test):\n        predictions = []\n        X_test = X_test.values  # Convert to NumPy array\n        for test_point in X_test:\n            # Calculate distances from the test point to all training points\n            distances = self.euclidean_distance(self.X_train, test_point)\n\n            # Get the indices of the k nearest neighbors\n            k_indices = np.argsort(distances)[:self.k]\n\n            # Get the labels of the k nearest neighbors\n            k_labels = self.y_train[k_indices]\n\n            # Majority voting: find the most frequent label manually\n            unique_labels, counts = np.unique(k_labels, return_counts=True)\n            majority_label = unique_labels[np.argmax(counts)]  # The label with the maximum count\n            predictions.append(majority_label)\n\n        return np.array(predictions)\n\n# Instantiate the KNN classifier with k=3\nknn = KNN(k=3)\n\n# Train the KNN classifier\nknn.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = knn.predict(X_test)\n\n# Confusion Matrix and Accuracy\nconf_matrix = confusion_matrix(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print Results\nprint(\"True Labels:\", y_test.values)  # Convert y_test to numpy array for printing\nprint(\"Predicted Labels:\", y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Accuracy:\", accuracy)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T16:23:28.176521Z","iopub.execute_input":"2025-01-23T16:23:28.176900Z","iopub.status.idle":"2025-01-23T16:23:28.199449Z","shell.execute_reply.started":"2025-01-23T16:23:28.176869Z","shell.execute_reply":"2025-01-23T16:23:28.198276Z"}},"outputs":[{"name":"stdout","text":"True Labels: [2 0 1 2 2 0 2 1 2 2 1 0 0 0 0 2 1 2 2 1 0 1 0 1 1 1 1 1 0 0]\nPredicted Labels: [2 0 1 2 2 0 2 1 2 2 1 0 0 0 0 2 1 2 2 1 0 1 0 1 1 1 1 1 0 0]\nConfusion Matrix:\n [[10  0  0]\n [ 0 11  0]\n [ 0  0  9]]\nAccuracy: 1.0\n","output_type":"stream"}],"execution_count":32}]}